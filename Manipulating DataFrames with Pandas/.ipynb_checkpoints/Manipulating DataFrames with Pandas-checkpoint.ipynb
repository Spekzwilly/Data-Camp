{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           winner   total  voters\n",
      "county                           \n",
      "Adams      Romney   41973   61156\n",
      "Allegheny   Obama  614671  924351\n",
      "Armstrong  Romney   28322   42147\n",
      "Beaver     Romney   80015  115157\n",
      "Bedford    Romney   21444   32189\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'pennsylvania2012_turnout.csv'\n",
    "# Read in filename and set the index: election\n",
    "election = pd.read_csv(filename, index_col='county')\n",
    "\n",
    "# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results\n",
    "results = election[['winner', 'total', 'voters']]\n",
    "\n",
    "# Print the output of results.head()\n",
    "print(results.head())\n",
    "#print(election.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total</th>\n",
       "      <th>Obama</th>\n",
       "      <th>Romney</th>\n",
       "      <th>winner</th>\n",
       "      <th>voters</th>\n",
       "      <th>turnout</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adams</th>\n",
       "      <td>PA</td>\n",
       "      <td>41973</td>\n",
       "      <td>35.482334</td>\n",
       "      <td>63.112001</td>\n",
       "      <td>Romney</td>\n",
       "      <td>61156</td>\n",
       "      <td>68.632677</td>\n",
       "      <td>27.629667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allegheny</th>\n",
       "      <td>PA</td>\n",
       "      <td>614671</td>\n",
       "      <td>56.640219</td>\n",
       "      <td>42.185820</td>\n",
       "      <td>Obama</td>\n",
       "      <td>924351</td>\n",
       "      <td>66.497575</td>\n",
       "      <td>14.454399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armstrong</th>\n",
       "      <td>PA</td>\n",
       "      <td>28322</td>\n",
       "      <td>30.696985</td>\n",
       "      <td>67.901278</td>\n",
       "      <td>Romney</td>\n",
       "      <td>42147</td>\n",
       "      <td>67.198140</td>\n",
       "      <td>37.204293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beaver</th>\n",
       "      <td>PA</td>\n",
       "      <td>80015</td>\n",
       "      <td>46.032619</td>\n",
       "      <td>52.637630</td>\n",
       "      <td>Romney</td>\n",
       "      <td>115157</td>\n",
       "      <td>69.483401</td>\n",
       "      <td>6.605012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedford</th>\n",
       "      <td>PA</td>\n",
       "      <td>21444</td>\n",
       "      <td>22.057452</td>\n",
       "      <td>76.986570</td>\n",
       "      <td>Romney</td>\n",
       "      <td>32189</td>\n",
       "      <td>66.619031</td>\n",
       "      <td>54.929118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          state   total      Obama     Romney  winner  voters    turnout  \\\n",
       "county                                                                     \n",
       "Adams        PA   41973  35.482334  63.112001  Romney   61156  68.632677   \n",
       "Allegheny    PA  614671  56.640219  42.185820   Obama  924351  66.497575   \n",
       "Armstrong    PA   28322  30.696985  67.901278  Romney   42147  67.198140   \n",
       "Beaver       PA   80015  46.032619  52.637630  Romney  115157  69.483401   \n",
       "Bedford      PA   21444  22.057452  76.986570  Romney   32189  66.619031   \n",
       "\n",
       "              margin  \n",
       "county                \n",
       "Adams      27.629667  \n",
       "Allegheny  14.454399  \n",
       "Armstrong  37.204293  \n",
       "Beaver      6.605012  \n",
       "Bedford    54.929118  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             state   total      Obama     Romney  winner   voters    turnout  \\\n",
      "county                                                                         \n",
      "Perry           PA   18240  29.769737  68.591009  Romney    27245  66.948064   \n",
      "Philadelphia    PA  653598  85.224251  14.051451   Obama  1099197  59.461407   \n",
      "Pike            PA   23164  43.904334  54.882576  Romney    41840  55.363289   \n",
      "Potter          PA    7205  26.259542  72.158223  Romney    10913  66.022175   \n",
      "\n",
      "                 margin  \n",
      "county                   \n",
      "Perry         38.821272  \n",
      "Philadelphia  71.172800  \n",
      "Pike          10.978242  \n",
      "Potter        45.898681  \n",
      "             state   total      Obama     Romney  winner   voters    turnout  \\\n",
      "county                                                                         \n",
      "Potter          PA    7205  26.259542  72.158223  Romney    10913  66.022175   \n",
      "Pike            PA   23164  43.904334  54.882576  Romney    41840  55.363289   \n",
      "Philadelphia    PA  653598  85.224251  14.051451   Obama  1099197  59.461407   \n",
      "Perry           PA   18240  29.769737  68.591009  Romney    27245  66.948064   \n",
      "\n",
      "                 margin  \n",
      "county                   \n",
      "Potter        45.898681  \n",
      "Pike          10.978242  \n",
      "Philadelphia  71.172800  \n",
      "Perry         38.821272  \n"
     ]
    }
   ],
   "source": [
    "# Slice the row labels 'Perry' to 'Potter': p_counties\n",
    "p_counties = election.loc['Perry':'Potter', :]\n",
    "\n",
    "# Print the p_counties DataFrame\n",
    "print(p_counties)\n",
    "\n",
    "# Slice the row labels 'Potter' to 'Perry' in reverse order: p_counties_rev\n",
    "p_counties_rev = election.loc['Potter':'Perry':-1]\n",
    "\n",
    "# Print the p_counties_rev DataFrame\n",
    "print(p_counties_rev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          state   total      Obama\n",
      "county                            \n",
      "Adams        PA   41973  35.482334\n",
      "Allegheny    PA  614671  56.640219\n",
      "Armstrong    PA   28322  30.696985\n",
      "Beaver       PA   80015  46.032619\n",
      "Bedford      PA   21444  22.057452\n",
      "               Obama     Romney  winner\n",
      "county                                 \n",
      "Adams      35.482334  63.112001  Romney\n",
      "Allegheny  56.640219  42.185820   Obama\n",
      "Armstrong  30.696985  67.901278  Romney\n",
      "Beaver     46.032619  52.637630  Romney\n",
      "Bedford    22.057452  76.986570  Romney\n",
      "              Romney  winner  voters    turnout     margin\n",
      "county                                                    \n",
      "Adams      63.112001  Romney   61156  68.632677  27.629667\n",
      "Allegheny  42.185820   Obama  924351  66.497575  14.454399\n",
      "Armstrong  67.901278  Romney   42147  67.198140  37.204293\n",
      "Beaver     52.637630  Romney  115157  69.483401   6.605012\n",
      "Bedford    76.986570  Romney   32189  66.619031  54.929118\n"
     ]
    }
   ],
   "source": [
    "# Slice the columns from the starting column to 'Obama': left_columns\n",
    "left_columns = election.loc[:,:'Obama']\n",
    "\n",
    "# Print the output of left_columns.head()\n",
    "print(left_columns.head())\n",
    "\n",
    "# Slice the columns from 'Obama' to 'winner': middle_columns\n",
    "middle_columns = election.loc[:,'Obama':'winner']\n",
    "\n",
    "# Print the output of middle_columns.head()\n",
    "print(middle_columns.head())\n",
    "\n",
    "# Slice the columns from 'Romney' to the end: 'right_columns'\n",
    "right_columns = election.loc[:,'Romney':]\n",
    "\n",
    "# Print the output of right_columns.head()\n",
    "print(right_columns.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subselecting DataFrames with lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              winner      Obama     Romney\n",
      "county                                    \n",
      "Philadelphia   Obama  85.224251  14.051451\n",
      "Centre        Romney  48.948416  48.977486\n",
      "Fulton        Romney  21.096291  77.748861\n"
     ]
    }
   ],
   "source": [
    "# Create the list of row labels: rows\n",
    "rows = ['Philadelphia', 'Centre', 'Fulton']\n",
    "\n",
    "# Create the list of column labels: cols\n",
    "cols = ['winner', 'Obama', 'Romney']\n",
    "\n",
    "# Create the new DataFrame: three_counties\n",
    "three_counties = election.loc[rows, cols]\n",
    "\n",
    "# Print the three_counties DataFrame\n",
    "print(three_counties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total</th>\n",
       "      <th>Obama</th>\n",
       "      <th>Romney</th>\n",
       "      <th>winner</th>\n",
       "      <th>voters</th>\n",
       "      <th>turnout</th>\n",
       "      <th>margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bucks</th>\n",
       "      <td>PA</td>\n",
       "      <td>319407</td>\n",
       "      <td>49.966970</td>\n",
       "      <td>48.801686</td>\n",
       "      <td>Obama</td>\n",
       "      <td>435606</td>\n",
       "      <td>73.324748</td>\n",
       "      <td>1.165284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Butler</th>\n",
       "      <td>PA</td>\n",
       "      <td>88924</td>\n",
       "      <td>31.920516</td>\n",
       "      <td>66.816607</td>\n",
       "      <td>Romney</td>\n",
       "      <td>122762</td>\n",
       "      <td>72.436096</td>\n",
       "      <td>34.896091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chester</th>\n",
       "      <td>PA</td>\n",
       "      <td>248295</td>\n",
       "      <td>49.228539</td>\n",
       "      <td>49.650617</td>\n",
       "      <td>Romney</td>\n",
       "      <td>337822</td>\n",
       "      <td>73.498766</td>\n",
       "      <td>0.422079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forest</th>\n",
       "      <td>PA</td>\n",
       "      <td>2308</td>\n",
       "      <td>38.734835</td>\n",
       "      <td>59.835355</td>\n",
       "      <td>Romney</td>\n",
       "      <td>3232</td>\n",
       "      <td>71.410891</td>\n",
       "      <td>21.100520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franklin</th>\n",
       "      <td>PA</td>\n",
       "      <td>62802</td>\n",
       "      <td>30.110506</td>\n",
       "      <td>68.583803</td>\n",
       "      <td>Romney</td>\n",
       "      <td>87406</td>\n",
       "      <td>71.850903</td>\n",
       "      <td>38.473297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montgomery</th>\n",
       "      <td>PA</td>\n",
       "      <td>401787</td>\n",
       "      <td>56.637223</td>\n",
       "      <td>42.286834</td>\n",
       "      <td>Obama</td>\n",
       "      <td>551105</td>\n",
       "      <td>72.905708</td>\n",
       "      <td>14.350390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westmoreland</th>\n",
       "      <td>PA</td>\n",
       "      <td>168709</td>\n",
       "      <td>37.567646</td>\n",
       "      <td>61.306154</td>\n",
       "      <td>Romney</td>\n",
       "      <td>238006</td>\n",
       "      <td>70.884347</td>\n",
       "      <td>23.738508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state   total      Obama     Romney  winner  voters    turnout  \\\n",
       "county                                                                        \n",
       "Bucks           PA  319407  49.966970  48.801686   Obama  435606  73.324748   \n",
       "Butler          PA   88924  31.920516  66.816607  Romney  122762  72.436096   \n",
       "Chester         PA  248295  49.228539  49.650617  Romney  337822  73.498766   \n",
       "Forest          PA    2308  38.734835  59.835355  Romney    3232  71.410891   \n",
       "Franklin        PA   62802  30.110506  68.583803  Romney   87406  71.850903   \n",
       "Montgomery      PA  401787  56.637223  42.286834   Obama  551105  72.905708   \n",
       "Westmoreland    PA  168709  37.567646  61.306154  Romney  238006  70.884347   \n",
       "\n",
       "                 margin  \n",
       "county                   \n",
       "Bucks          1.165284  \n",
       "Butler        34.896091  \n",
       "Chester        0.422079  \n",
       "Forest        21.100520  \n",
       "Franklin      38.473297  \n",
       "Montgomery    14.350390  \n",
       "Westmoreland  23.738508  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the boolean array: high_turnout\n",
    "high_turnout = election['turnout'] > 70\n",
    "\n",
    "# Filter the election DataFrame with the high_turnout array: high_turnout_df\n",
    "high_turnout_df = election[high_turnout]\n",
    "\n",
    "# Print the high_turnout_results DataFrame\n",
    "high_turnout_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering columns using other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67 entries, Adams to York\n",
      "Data columns (total 8 columns):\n",
      "state      67 non-null object\n",
      "total      67 non-null int64\n",
      "Obama      67 non-null float64\n",
      "Romney     67 non-null float64\n",
      "winner     64 non-null object\n",
      "voters     67 non-null int64\n",
      "turnout    67 non-null float64\n",
      "margin     67 non-null float64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 7.2+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\willy huang\\python\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create the boolean array: too_close\n",
    "too_close = election['margin'] < 1\n",
    "\n",
    "# Assign np.nan to the 'winner' column where the results were too close to call\n",
    "election['winner'][too_close] = np.nan\n",
    "\n",
    "# Print the output of election.info()\n",
    "print(election.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "     age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.00      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.92      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.00      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.00      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.00      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 2)\n",
      "(272, 2)\n",
      "(1069, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "pclass      1309 non-null int64\n",
      "survived    1309 non-null int64\n",
      "name        1309 non-null object\n",
      "sex         1309 non-null object\n",
      "age         1046 non-null float64\n",
      "sibsp       1309 non-null int64\n",
      "parch       1309 non-null int64\n",
      "ticket      1309 non-null object\n",
      "fare        1308 non-null float64\n",
      "embarked    1307 non-null object\n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 102.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Select the 'age' and 'cabin' columns: df\n",
    "df = titanic[['age', 'cabin']]\n",
    "# To select the 'age' and 'cabin' columns, first create a list consisting of them, and pass them inside titanic[].\n",
    "\n",
    "\n",
    "# Print the shape of df\n",
    "print(df.shape)\n",
    "\n",
    "# Drop rows in df with how='any' and print the shape\n",
    "print(df.dropna(how='any').shape)\n",
    "\n",
    "# Drop rows in df with how='all' and print the shape\n",
    "print(df.dropna(how='all').shape)\n",
    "\n",
    "# Call .dropna() with thresh=1000 and axis='columns' and print the output of .info() from titanic\n",
    "print(titanic.dropna(thresh=1000, axis='columns').info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using apply() to transform a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Max TemperatureF</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "      <th>Min TemperatureF</th>\n",
       "      <th>Max Dew PointF</th>\n",
       "      <th>Mean Dew PointF</th>\n",
       "      <th>Min DewpointF</th>\n",
       "      <th>Max Humidity</th>\n",
       "      <th>Mean Humidity</th>\n",
       "      <th>Min Humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>Max VisibilityMiles</th>\n",
       "      <th>Mean VisibilityMiles</th>\n",
       "      <th>Min VisibilityMiles</th>\n",
       "      <th>Max Wind SpeedMPH</th>\n",
       "      <th>Mean Wind SpeedMPH</th>\n",
       "      <th>Max Gust SpeedMPH</th>\n",
       "      <th>PrecipitationIn</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-1-1</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>Snow</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-1-2</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-1-3</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-1-4</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-1-5</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Max TemperatureF  Mean TemperatureF  Min TemperatureF  \\\n",
       "0  2013-1-1                32                 28                21   \n",
       "1  2013-1-2                25                 21                17   \n",
       "2  2013-1-3                32                 24                16   \n",
       "3  2013-1-4                30                 28                27   \n",
       "4  2013-1-5                34                 30                25   \n",
       "\n",
       "   Max Dew PointF  Mean Dew PointF  Min DewpointF  Max Humidity  \\\n",
       "0              30               27             16           100   \n",
       "1              14               12             10            77   \n",
       "2              19               15              9            77   \n",
       "3              21               19             17            75   \n",
       "4              23               20             16            75   \n",
       "\n",
       "   Mean Humidity  Min Humidity       ...        Max VisibilityMiles  \\\n",
       "0             89            77       ...                         10   \n",
       "1             67            55       ...                         10   \n",
       "2             67            56       ...                         10   \n",
       "3             68            59       ...                         10   \n",
       "4             68            61       ...                         10   \n",
       "\n",
       "   Mean VisibilityMiles  Min VisibilityMiles  Max Wind SpeedMPH  \\\n",
       "0                     6                    2                 10   \n",
       "1                    10                   10                 14   \n",
       "2                    10                   10                 17   \n",
       "3                    10                    6                 23   \n",
       "4                    10                   10                 16   \n",
       "\n",
       "   Mean Wind SpeedMPH  Max Gust SpeedMPH  PrecipitationIn   CloudCover  \\\n",
       "0                   8                NaN             0.00            8   \n",
       "1                   5                NaN             0.00            4   \n",
       "2                   8               26.0             0.00            3   \n",
       "3                  16               32.0             0.00            4   \n",
       "4                  10               23.0             0.21            5   \n",
       "\n",
       "   Events  WindDirDegrees  \n",
       "0    Snow             277  \n",
       "1     NaN             272  \n",
       "2     NaN             229  \n",
       "3     NaN             250  \n",
       "4     NaN             221  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('pittsburgh2013.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean TemperatureC  Mean Dew PointC\n",
      "0          -2.222222        -2.777778\n",
      "1          -6.111111       -11.111111\n",
      "2          -4.444444        -9.444444\n",
      "3          -2.222222        -7.222222\n",
      "4          -1.111111        -6.666667\n"
     ]
    }
   ],
   "source": [
    "# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius\n",
    "def to_celsius(F):\n",
    "    return 5/9*(F - 32)\n",
    "\n",
    "# Apply the function over 'Mean TemperatureF' and 'Mean Dew PointF': df_celsius\n",
    "df_celsius = weather[['Mean TemperatureF', 'Mean Dew PointF']].apply(to_celsius)\n",
    "\n",
    "# Reassign the columns df_celsius\n",
    "df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']\n",
    "\n",
    "# Print the output of df_celsius.head()\n",
    "print(df_celsius.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .map() with a dictionary\n",
    "#### The .map() method is used to transform values according to a Python dictionary look-up. In this exercise you'll practice this method while returning to working with the election DataFrame, which has been pre-loaded for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          state   total      Obama     Romney  winner  voters    turnout  \\\n",
      "county                                                                     \n",
      "Adams        PA   41973  35.482334  63.112001  Romney   61156  68.632677   \n",
      "Allegheny    PA  614671  56.640219  42.185820   Obama  924351  66.497575   \n",
      "Armstrong    PA   28322  30.696985  67.901278  Romney   42147  67.198140   \n",
      "Beaver       PA   80015  46.032619  52.637630  Romney  115157  69.483401   \n",
      "Bedford      PA   21444  22.057452  76.986570  Romney   32189  66.619031   \n",
      "\n",
      "              margin color  \n",
      "county                      \n",
      "Adams      27.629667   red  \n",
      "Allegheny  14.454399  blue  \n",
      "Armstrong  37.204293   red  \n",
      "Beaver      6.605012   red  \n",
      "Bedford    54.929118   red  \n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary: red_vs_blue\n",
    "red_vs_blue = {\n",
    "    'Obama': 'blue',\n",
    "    'Romney': 'red'\n",
    "}\n",
    "\n",
    "# Use the dictionary to map the 'winner' column to the new column: election['color']\n",
    "election['color'] = election['winner'].map(red_vs_blue)\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using vectorized functions\n",
    "#### Instead of using .apply() as you did in the earlier exercises, the zscore UFunc will take a pandas Series as input and return a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "          state   total      Obama     Romney  winner  voters    turnout  \\\n",
      "county                                                                     \n",
      "Adams        PA   41973  35.482334  63.112001  Romney   61156  68.632677   \n",
      "Allegheny    PA  614671  56.640219  42.185820   Obama  924351  66.497575   \n",
      "Armstrong    PA   28322  30.696985  67.901278  Romney   42147  67.198140   \n",
      "Beaver       PA   80015  46.032619  52.637630  Romney  115157  69.483401   \n",
      "Bedford      PA   21444  22.057452  76.986570  Romney   32189  66.619031   \n",
      "\n",
      "              margin color  turnout_zscore  \n",
      "county                                      \n",
      "Adams      27.629667   red        0.853734  \n",
      "Allegheny  14.454399  blue        0.439846  \n",
      "Armstrong  37.204293   red        0.575650  \n",
      "Beaver      6.605012   red        1.018647  \n",
      "Bedford    54.929118   red        0.463391  \n"
     ]
    }
   ],
   "source": [
    "# Import zscore from scipy.stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "# Call zscore with election['turnout'] as input: turnout_zscore\n",
    "turnout_zscore = zscore(election['turnout'])\n",
    "\n",
    "# Print the type of turnout_zscore\n",
    "print(type(turnout_zscore))\n",
    "\n",
    "# Assign turnout_zscore to a new column: election['turnout_zscore']\n",
    "election['turnout_zscore'] = turnout_zscore\n",
    "\n",
    "# Print the output of election.head()\n",
    "print(election.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing index of a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eggs</th>\n",
       "      <th>salt</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>47</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>110</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>221</td>\n",
       "      <td>89.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>77</td>\n",
       "      <td>87.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eggs  salt  spam\n",
       "month                  \n",
       "Jan      47  12.0    17\n",
       "Feb     110  50.0    31\n",
       "Mar     221  89.0    72\n",
       "Apr      77  87.0    20\n",
       "May     132   NaN    52"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales.csv', index_col='month')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eggs  salt  spam\n",
      "JAN    47  12.0    17\n",
      "FEB   110  50.0    31\n",
      "MAR   221  89.0    72\n",
      "APR    77  87.0    20\n",
      "MAY   132   NaN    52\n",
      "JUN   205  60.0    55\n"
     ]
    }
   ],
   "source": [
    "# Create the list of new indexes: new_idx\n",
    "new_idx = [i.upper() for i in sales.index]\n",
    "\n",
    "# Assign new_idx to sales.index\n",
    "sales.index = new_idx\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        eggs  salt  spam\n",
      "MONTHS                  \n",
      "JAN       47  12.0    17\n",
      "FEB      110  50.0    31\n",
      "MAR      221  89.0    72\n",
      "APR       77  87.0    20\n",
      "MAY      132   NaN    52\n",
      "JUN      205  60.0    55\n",
      "PRODUCTS  eggs  salt  spam\n",
      "MONTHS                    \n",
      "JAN         47  12.0    17\n",
      "FEB        110  50.0    31\n",
      "MAR        221  89.0    72\n",
      "APR         77  87.0    20\n",
      "MAY        132   NaN    52\n",
      "JUN        205  60.0    55\n"
     ]
    }
   ],
   "source": [
    "## Changing index name labels\n",
    "\n",
    "# Assign the string 'MONTHS' to sales.index.name\n",
    "sales.index.name = 'MONTHS'\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Assign the string 'PRODUCTS' to sales.columns.name \n",
    "sales.columns.name = 'PRODUCTS'\n",
    "\n",
    "# Print the sales dataframe again\n",
    "print(sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an index, then a DataFrame\n",
    "#### You can also build the DataFrame and index independently, and then put them together. If you take this route, be careful, as any mistakes in generating the DataFrame or the index can cause the data and the index to be aligned incorrectly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTS  eggs  salt  spam\n",
      "Jan         47  12.0    17\n",
      "Feb        110  50.0    31\n",
      "Mar        221  89.0    72\n",
      "Apr         77  87.0    20\n",
      "May        132   NaN    52\n",
      "Jun        205  60.0    55\n"
     ]
    }
   ],
   "source": [
    "# Generate the list of months: months\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\n",
    "\n",
    "# Assign months to sales.index\n",
    "sales.index = months\n",
    "\n",
    "# Print the modified sales DataFrame\n",
    "print(sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ['CA', 'CA', 'NY', 'NY', 'TX', 'TX']\n",
    "month = [1, 2, 1, 2, 1, 2]\n",
    "sales['state'] = state\n",
    "sales['month'] = month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting & sorting a MultiIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCTS     eggs  salt  spam\n",
      "state month                  \n",
      "CA    1        47  12.0    17\n",
      "      2       110  50.0    31\n",
      "NY    1       221  89.0    72\n",
      "      2        77  87.0    20\n",
      "TX    1       132   NaN    52\n",
      "      2       205  60.0    55\n"
     ]
    }
   ],
   "source": [
    "# Set the index to be the columns ['state', 'month']: sales\n",
    "sales = sales.set_index(['state', 'month'])\n",
    "\n",
    "# Sort the MultiIndex: sales\n",
    "sales = sales.sort_index()\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using .loc[] with nonunique indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3064\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3065\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-b80b5c207865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set the index to the column 'state': sales\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print the sales DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msales\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   3907\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3908\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3909\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3910\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3911\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3064\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'state'"
     ]
    }
   ],
   "source": [
    "# Set the index to the column 'state': sales\n",
    "sales = sales.set_index(['state'])\n",
    "\n",
    "# Print the sales DataFrame\n",
    "print(sales)\n",
    "\n",
    "# Access the data from 'NY'\n",
    "print(sales.loc['NY',:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up data for NY in month 1: NY_month1\n",
    "NY_month1 = sales.loc[('NY', 1),:]\n",
    "\n",
    "# Look up data for CA and TX in month 2: CA_TX_month2\n",
    "CA_TX_month2 = sales.loc[(['CA', 'TX'], 2),:]\n",
    "\n",
    "# Look up data for all states in month 2: all_month2\n",
    "all_month2 = sales.loc[(slice(None), 2),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCTS\n",
       "eggs    221.0\n",
       "salt     89.0\n",
       "spam     72.0\n",
       "Name: (NY, 1), dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NY_month1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTS</th>\n",
       "      <th>eggs</th>\n",
       "      <th>salt</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <th>2</th>\n",
       "      <td>205</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PRODUCTS     eggs  salt  spam\n",
       "state month                  \n",
       "CA    2       110  50.0    31\n",
       "TX    2       205  60.0    55"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_TX_month2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCTS</th>\n",
       "      <th>eggs</th>\n",
       "      <th>salt</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>87.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <th>2</th>\n",
       "      <td>205</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PRODUCTS     eggs  salt  spam\n",
       "state month                  \n",
       "CA    2       110  50.0    31\n",
       "NY    2        77  87.0    20\n",
       "TX    2       205  60.0    55"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_month2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting a single variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>weekday</th>\n",
       "      <th>city</th>\n",
       "      <th>visitors</th>\n",
       "      <th>signups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Austin</td>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>237</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Austin</td>\n",
       "      <td>326</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mon</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>456</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 weekday    city  visitors  signups\n",
       "0           0     Sun  Austin       139        7\n",
       "1           1     Sun  Dallas       237       12\n",
       "2           2     Mon  Austin       326        3\n",
       "3           3     Mon  Dallas       456        5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('users.csv')\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city     Austin  Dallas\n",
      "weekday                \n",
      "Mon         326     456\n",
      "Sun         139     237\n"
     ]
    }
   ],
   "source": [
    "# Pivot the users DataFrame: visitors_pivot\n",
    "visitors_pivot = users.pivot(index='weekday', columns='city', values='visitors')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(visitors_pivot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city     Austin  Dallas\n",
      "weekday                \n",
      "Mon           3       5\n",
      "Sun           7      12\n",
      "        Unnamed: 0        visitors        signups       \n",
      "city        Austin Dallas   Austin Dallas  Austin Dallas\n",
      "weekday                                                 \n",
      "Mon              2      3      326    456       3      5\n",
      "Sun              0      1      139    237       7     12\n"
     ]
    }
   ],
   "source": [
    "# Pivot users with signups indexed by weekday and city: signups_pivot\n",
    "signups_pivot = users.pivot(index='weekday', columns='city', values='signups')\n",
    "\n",
    "# Print signups_pivot\n",
    "print(signups_pivot)\n",
    "\n",
    "# Pivot users pivoted by both signups and visitors: pivot\n",
    "pivot = users.pivot(index='weekday', columns='city')\n",
    "\n",
    "# Print the pivoted DataFrame\n",
    "print(pivot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking & unstacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting DataFrames\n",
    "## Adding names for readability\n",
    "### the goal of melting is to restore a pivoted DataFrame to its original form, or to change it from a wide shape to a long shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 weekday    city  visitors  signups\n",
      "0           0     Sun  Austin       139        7\n",
      "1           1     Sun  Dallas       237       12\n",
      "2           2     Mon  Austin       326        3\n",
      "3           3     Mon  Dallas       456        5\n",
      "   weekday    city    variable  visitors\n",
      "0      Sun  Austin  Unnamed: 0         0\n",
      "1      Sun  Dallas  Unnamed: 0         1\n",
      "2      Mon  Austin  Unnamed: 0         2\n",
      "3      Mon  Dallas  Unnamed: 0         3\n",
      "4      Sun  Austin    visitors       139\n",
      "5      Sun  Dallas    visitors       237\n",
      "6      Mon  Austin    visitors       326\n",
      "7      Mon  Dallas    visitors       456\n",
      "8      Sun  Austin     signups         7\n",
      "9      Sun  Dallas     signups        12\n",
      "10     Mon  Austin     signups         3\n",
      "11     Mon  Dallas     signups         5\n"
     ]
    }
   ],
   "source": [
    "# Reset the index: visitors_by_city_weekday\n",
    "#users = users.reset_index()\n",
    "\n",
    "# Print visitors_by_city_weekday\n",
    "print(users)\n",
    "\n",
    "# Melt visitors_by_city_weekday: visitors\n",
    "visitors = pd.melt(users, id_vars=['weekday','city'], value_name='visitors')\n",
    "\n",
    "# Print visitors\n",
    "print(visitors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   weekday    city    variable  value\n",
      "0      Sun  Austin  Unnamed: 0      0\n",
      "1      Sun  Dallas  Unnamed: 0      1\n",
      "2      Mon  Austin  Unnamed: 0      2\n",
      "3      Mon  Dallas  Unnamed: 0      3\n",
      "4      Sun  Austin    visitors    139\n",
      "5      Sun  Dallas    visitors    237\n",
      "6      Mon  Austin    visitors    326\n",
      "7      Mon  Dallas    visitors    456\n",
      "8      Sun  Austin     signups      7\n",
      "9      Sun  Dallas     signups     12\n",
      "10     Mon  Austin     signups      3\n",
      "11     Mon  Dallas     signups      5\n"
     ]
    }
   ],
   "source": [
    "# Melt users: skinny\n",
    "skinny = pd.melt(users, id_vars=['weekday','city'])\n",
    "\n",
    "# Print skinny\n",
    "print(skinny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>city</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Austin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Austin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Austin</td>\n",
       "      <td>index</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>visitors</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Austin</td>\n",
       "      <td>visitors</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>visitors</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Austin</td>\n",
       "      <td>signups</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>signups</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Austin</td>\n",
       "      <td>signups</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mon</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>signups</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday    city  variable  value\n",
       "0      Sun  Austin       NaN      0\n",
       "1      Sun  Dallas       NaN      1\n",
       "2      Mon  Austin       NaN      2\n",
       "3      Mon  Dallas       NaN      3\n",
       "4      Sun  Austin     index    139\n",
       "5      Sun  Dallas  visitors    237\n",
       "6      Mon  Austin  visitors    326\n",
       "7      Mon  Dallas  visitors    456\n",
       "8      Sun  Austin   signups      7\n",
       "9      Sun  Dallas   signups     12\n",
       "10     Mon  Austin   signups      3\n",
       "11     Mon  Dallas   signups      5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skinny.loc[:3, 'variable'] = 'NaN'\n",
    "\n",
    "skinny.loc[4,'variable'] = 'index'\n",
    "skinny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining key-value pairs with melt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Unnamed: 0  visitors  signups\n",
      "city   weekday                               \n",
      "Austin Sun               0       139        7\n",
      "Dallas Sun               1       237       12\n",
      "Austin Mon               2       326        3\n",
      "Dallas Mon               3       456        5\n",
      "      variable  visitors\n",
      "0   Unnamed: 0         0\n",
      "1   Unnamed: 0         1\n",
      "2   Unnamed: 0         2\n",
      "3   Unnamed: 0         3\n",
      "4     visitors       139\n",
      "5     visitors       237\n",
      "6     visitors       326\n",
      "7     visitors       456\n",
      "8      signups         7\n",
      "9      signups        12\n",
      "10     signups         3\n",
      "11     signups         5\n"
     ]
    }
   ],
   "source": [
    "# Set the new index: users_idx\n",
    "users_idx = users.set_index(['city', 'weekday'])\n",
    "\n",
    "# Print the users_idx DataFrame\n",
    "print(users_idx)\n",
    "\n",
    "# Obtain the key-value pairs: kv_pairs\n",
    "kv_pairs = pd.melt(users_idx, col_level=0, value_name='visitors')\n",
    "\n",
    "# Print the key-value pairs\n",
    "print(kv_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0        signups        visitors       \n",
      "city        Austin Dallas  Austin Dallas   Austin Dallas\n",
      "weekday                                                 \n",
      "Mon              2      3       3      5      326    456\n",
      "Sun              0      1       7     12      139    237\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame with the appropriate pivot table: by_city_day\n",
    "by_city_day = users.pivot_table(index='weekday', columns='city')\n",
    "\n",
    "# Print by_city_day\n",
    "print(by_city_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using other aggregations in pivot tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  city  signups  visitors\n",
      "weekday                                     \n",
      "Mon               2     2        2         2\n",
      "Sun               2     2        2         2\n",
      "==========================================\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Use a pivot table to display the count of each column: count_by_weekday1\n",
    "count_by_weekday1 = users.pivot_table(index='weekday',aggfunc='count')\n",
    "\n",
    "# Print count_by_weekday\n",
    "print(count_by_weekday1)\n",
    "\n",
    "# Replace 'aggfunc='count'' with 'aggfunc=len': count_by_weekday2\n",
    "count_by_weekday2 = users.pivot_table(index='weekday', aggfunc=len)\n",
    "# Verify that the same result is obtained\n",
    "print('==========================================')\n",
    "print(count_by_weekday1.equals(count_by_weekday2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using margins in pivot tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0  signups  visitors\n",
      "weekday                               \n",
      "Mon               5        8       782\n",
      "Sun               1       19       376\n",
      "         Unnamed: 0  signups  visitors\n",
      "weekday                               \n",
      "Mon               5        8       782\n",
      "Sun               1       19       376\n",
      "All               6       27      1158\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame with the appropriate pivot table: signups_and_visitors\n",
    "signups_and_visitors = users.pivot_table(index='weekday', aggfunc=sum)\n",
    "\n",
    "# Print signups_and_visitors\n",
    "print(signups_and_visitors)\n",
    "\n",
    "# Add in the margins: signups_and_visitors_total \n",
    "signups_and_visitors_total = users.pivot_table(index='weekday',aggfunc=sum,margins=True)\n",
    "\n",
    "# Print signups_and_visitors_total\n",
    "print(signups_and_visitors_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by multiple columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "1    323\n",
      "2    277\n",
      "3    709\n",
      "Name: survived, dtype: int64\n",
      "embarked  pclass\n",
      "C         1         141\n",
      "          2          28\n",
      "          3         101\n",
      "Q         1           3\n",
      "          2           7\n",
      "          3         113\n",
      "S         1         177\n",
      "          2         242\n",
      "          3         495\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Group titanic by 'pclass'\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Aggregate 'survived' column of by_class by count\n",
    "count_by_class = by_class['survived'].count()\n",
    "\n",
    "# Print count_by_class\n",
    "print(count_by_class)\n",
    "\n",
    "# Group titanic by 'embarked' and 'pclass'\n",
    "by_mult = titanic.groupby(['embarked','pclass'])\n",
    "\n",
    "# Aggregate 'survived' column of by_mult by count\n",
    "count_mult = by_mult['survived'].count()\n",
    "\n",
    "# Print count_mult\n",
    "print(count_mult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by another series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group life by regions['region']: life_by_region\n",
    "# life_by_region = life.groupby(regions['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "1    80.0\n",
      "2    70.0\n",
      "3    74.0\n",
      "Name: (age, max), dtype: float64\n",
      "pclass\n",
      "1    60.0000\n",
      "2    15.0458\n",
      "3     8.0500\n",
      "Name: (fare, median), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group titanic by 'pclass': by_class\n",
    "by_class = titanic.groupby('pclass')\n",
    "\n",
    "# Select 'age' and 'fare'\n",
    "by_class_sub = by_class[['age','fare']]\n",
    "\n",
    "# Aggregate by_class_sub by 'max' and 'median': aggregated\n",
    "aggregated = by_class_sub.agg(['max', 'median'])\n",
    "\n",
    "# Print the maximum age in each class\n",
    "print(aggregated.loc[:, ('age','max')])\n",
    "\n",
    "# Print the median fare in each class\n",
    "print(aggregated.loc[:, ('fare', 'median')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating on index levels/fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   population  child_mortality       gdp\n",
      "Year region                                                             \n",
      "2013 America                     9.629087e+08        17.745833   49634.0\n",
      "     East Asia & Pacific         2.244209e+09        22.285714  134744.0\n",
      "     Europe & Central Asia       8.968788e+08         9.831875   86418.0\n",
      "     Middle East & North Africa  4.030504e+08        20.221500  128676.0\n",
      "     South Asia                  1.701241e+09        46.287500   11469.0\n",
      "     Sub-Saharan Africa          9.205996e+08        76.944490   32035.0\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame and sort the index: gapminder\n",
    "gapminder = pd.read_csv('gapminder_tidy.csv', index_col=['Year', 'region', 'Country']).sort_index()\n",
    "\n",
    "# Group gapminder by 'Year' and 'region': by_year_region\n",
    "by_year_region = gapminder.groupby(['Year', 'region'])\n",
    "\n",
    "# Define the function to compute spread: spread\n",
    "def spread(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "# Create the dictionary: aggregator\n",
    "aggregator = {'population':'sum', 'child_mortality':'mean', 'gdp':spread}\n",
    "\n",
    "# Aggregate by_year_region using the dictionary: aggregated\n",
    "aggregated = by_year_region.agg(aggregator)\n",
    "\n",
    "# Print the last 6 entries of aggregated \n",
    "print(aggregated.tail(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping on a function of the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-4c73048e2747>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Read file: sales\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sales.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1756\u001b[0m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m                     \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m                 \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1815\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1816\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read file: sales\n",
    "sales = pd.read_csv('sales.csv',index_col='Date', parse_dates=True)\n",
    "\n",
    "\n",
    "# Create a groupby object: by_day\n",
    "by_day = sales.groupby(sales.index.strftime('%a'))\n",
    "\n",
    "# Create sum: units_sum\n",
    "units_sum = by_day['Units'].sum()\n",
    "\n",
    "# Print units_sum\n",
    "print(units_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting outliers with Z-Scores\n",
    "### As Dhavide demonstrated in the video using the zscore function, you can apply a .transform() method after grouping to apply a function to groups of data independently. The z-score is also useful to find outliers: a z-score value of +/- 3 is generally considered to be an outlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Year  fertility    life  population  child_mortality     gdp  \\\n",
      "Country                                                                      \n",
      "Bolivia       1964      6.607  43.913   3668568.0           265.40  2971.0   \n",
      "Bolivia       1965      6.593  44.229   3752892.0           260.10  3046.0   \n",
      "Bolivia       1966      6.586  44.536   3839751.0           254.50  3191.0   \n",
      "Bolivia       1967      6.585  44.835   3929192.0           248.80  3312.0   \n",
      "Bolivia       1968      6.587  45.132   4021551.0           243.00  3510.0   \n",
      "Bolivia       1969      6.587  45.436   4117259.0           237.10  3581.0   \n",
      "Bolivia       1970      6.578  45.765   4216572.0           231.30  3678.0   \n",
      "Bolivia       1971      6.549  46.135   4319564.0           225.30  3727.0   \n",
      "Bolivia       1972      6.496  46.563   4426012.0           219.10  3823.0   \n",
      "Bolivia       1973      6.415  47.055   4535500.0           212.80  3988.0   \n",
      "Bolivia       1974      6.310  47.614   4647442.0           206.40  4093.0   \n",
      "Bolivia       1975      6.183  48.242   4761344.0           200.10  4260.0   \n",
      "Cambodia      1973      5.988  35.800   7162333.0           273.01  1161.0   \n",
      "Cambodia      1974      5.795  33.100   7157572.0           290.92  1101.0   \n",
      "Cambodia      1975      5.622  19.800   7097800.0           310.00  1096.0   \n",
      "Cambodia      1976      5.498  17.100   6972559.0           285.60  1116.0   \n",
      "Cambodia      1977      5.441  16.100   6796368.0           261.90   976.0   \n",
      "Cambodia      1978      5.459  17.500   6618684.0           235.90  1003.0   \n",
      "Cambodia      1979      5.545  19.800   6506208.0           207.80   891.0   \n",
      "Cambodia      1980      5.685  26.000   6505693.0           181.40   839.0   \n",
      "Cambodia      1981      5.850  35.788   6636869.0           159.10   822.0   \n",
      "Guatemala     1964      6.434  47.884   4636016.0           201.50  3722.0   \n",
      "Haiti         1964      6.233  44.464   4188276.0           273.00  2024.0   \n",
      "Haiti         1965      6.179  45.006   4272760.0           268.50  2003.0   \n",
      "Haiti         1966      6.109  45.518   4359031.0           263.90  1949.0   \n",
      "Haiti         1967      6.026  45.994   4446944.0           259.20  1869.0   \n",
      "Haiti         1968      5.937  46.430   4535485.0           254.60  1902.0   \n",
      "Haiti         1969      5.847  46.831   4623315.0           249.90  1922.0   \n",
      "Haiti         1970      5.762  47.204   4709644.0           245.10  1970.0   \n",
      "Haiti         1971      5.693  47.561   4794158.0           240.10  2076.0   \n",
      "...            ...        ...     ...         ...              ...     ...   \n",
      "Haiti         2010      3.350  45.000   9993247.0           208.80  1518.0   \n",
      "Rwanda        1994      6.416   6.000   5648306.0           293.80   509.0   \n",
      "Timor-Leste   1964      6.347  35.724    537278.0           318.95   701.0   \n",
      "Timor-Leste   1965      6.314  36.263    547681.0           310.06   701.0   \n",
      "Timor-Leste   1966      6.268  36.885    558110.0           301.20   702.0   \n",
      "Timor-Leste   1974      5.037  36.648    662785.0           275.29   725.0   \n",
      "Timor-Leste   1975      4.794  35.080    662962.0           274.87   742.0   \n",
      "Timor-Leste   1976      4.611  33.702    652072.0           274.44   759.0   \n",
      "Timor-Leste   1977      4.514  32.814    632134.0           274.01   776.0   \n",
      "Timor-Leste   1978      4.513  32.615    608743.0           273.58   794.0   \n",
      "Timor-Leste   1979      4.606  33.162    589744.0           273.14   813.0   \n",
      "Timor-Leste   1980      4.767  34.402    580707.0           330.93   832.0   \n",
      "Timor-Leste   1981      4.956  36.166    583764.0           312.32   851.0   \n",
      "Turkey        1964      6.029  48.313  31109820.0           221.90  5296.0   \n",
      "Turkey        1965      5.951  49.037  31837999.0           215.40  5309.0   \n",
      "Turkey        1966      5.874  49.736  32556294.0           209.30  5906.0   \n",
      "Turkey        1967      5.797  50.409  33267998.0           203.40  6020.0   \n",
      "Turkey        1968      5.721  51.057  33982141.0           197.80  6295.0   \n",
      "Turkey        1969      5.644  51.683  34711167.0           192.30  6470.0   \n",
      "Turkey        1970      5.563  52.291  35464196.0           186.90  6740.0   \n",
      "Turkey        1971      5.475  52.893  36245756.0           181.50  6765.0   \n",
      "Turkey        1972      5.375  53.498  37054168.0           175.90  7186.0   \n",
      "Turkey        1973      5.263  54.115  37884870.0           170.30  7442.0   \n",
      "Turkey        1974      5.140  54.746  38730367.0           164.50  7991.0   \n",
      "Turkey        1975      5.008  55.392  39585821.0           158.60  8381.0   \n",
      "Turkey        1976      4.872  56.050  40446729.0           152.70  9142.0   \n",
      "Turkmenistan  1964      6.663  56.181   1829697.0           132.98  7952.0   \n",
      "Yemen, Rep.   1964      7.385  36.068   5527652.0              NaN     NaN   \n",
      "Yemen, Rep.   1965      7.418  36.957   5632206.0              NaN     NaN   \n",
      "Yemen, Rep.   1966      7.447  37.827   5737000.0              NaN     NaN   \n",
      "\n",
      "                                  region  \n",
      "Country                                   \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Bolivia                          America  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Cambodia             East Asia & Pacific  \n",
      "Guatemala                        America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "Haiti                            America  \n",
      "...                                  ...  \n",
      "Haiti                            America  \n",
      "Rwanda                Sub-Saharan Africa  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Timor-Leste          East Asia & Pacific  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkey             Europe & Central Asia  \n",
      "Turkmenistan       Europe & Central Asia  \n",
      "Yemen, Rep.   Middle East & North Africa  \n",
      "Yemen, Rep.   Middle East & North Africa  \n",
      "Yemen, Rep.   Middle East & North Africa  \n",
      "\n",
      "[62 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "gapminder_2010 = pd.read_csv('gapminder_tidy.csv', index_col='Country')\n",
    "\n",
    "# Import zscore\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Group gapminder_2010: standardized\n",
    "standardized = gapminder_2010.groupby('region')['life', 'fertility'].transform(zscore)\n",
    "\n",
    "# Construct a Boolean Series to identify outliers: outliers\n",
    "outliers = (standardized['life'] < -3) | (standardized['fertility'] > 3)\n",
    "\n",
    "# Filter gapminder_2010 by the outliers: gm_outliers\n",
    "gm_outliers = gapminder_2010.loc[outliers]\n",
    "\n",
    "# Print gm_outliers\n",
    "print(gm_outliers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing data (imputation) by group\n",
    "### Many statistical and machine learning packages cannot determine the best action to take when missing data entries are encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  survived                                     name     sex   age  \\\n",
      "1299       3         0                      Yasbeck, Mr. Antoni    male  27.0   \n",
      "1300       3         1  Yasbeck, Mrs. Antoni (Selini Alexander)  female  15.0   \n",
      "1301       3         0                     Youseff, Mr. Gerious    male  45.5   \n",
      "1302       3         0                        Yousif, Mr. Wazli    male  25.0   \n",
      "1303       3         0                    Yousseff, Mr. Gerious    male  25.0   \n",
      "1304       3         0                     Zabour, Miss. Hileni  female  14.5   \n",
      "1305       3         0                    Zabour, Miss. Thamine  female  22.0   \n",
      "1306       3         0                Zakarian, Mr. Mapriededer    male  26.5   \n",
      "1307       3         0                      Zakarian, Mr. Ortin    male  27.0   \n",
      "1308       3         0                       Zimmerman, Mr. Leo    male  29.0   \n",
      "\n",
      "      sibsp  parch  ticket     fare cabin embarked boat   body home.dest  \n",
      "1299      1      0    2659  14.4542   NaN        C    C    NaN       NaN  \n",
      "1300      1      0    2659  14.4542   NaN        C  NaN    NaN       NaN  \n",
      "1301      0      0    2628   7.2250   NaN        C  NaN  312.0       NaN  \n",
      "1302      0      0    2647   7.2250   NaN        C  NaN    NaN       NaN  \n",
      "1303      0      0    2627  14.4583   NaN        C  NaN    NaN       NaN  \n",
      "1304      1      0    2665  14.4542   NaN        C  NaN  328.0       NaN  \n",
      "1305      1      0    2665  14.4542   NaN        C  NaN    NaN       NaN  \n",
      "1306      0      0    2656   7.2250   NaN        C  NaN  304.0       NaN  \n",
      "1307      0      0    2670   7.2250   NaN        C  NaN    NaN       NaN  \n",
      "1308      0      0  315082   7.8750   NaN        S  NaN    NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = titanic.groupby(['sex', 'pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "\n",
    "# Impute age and assign to titanic['age']\n",
    "titanic.age = by_sex_class.age.transform(impute_median)\n",
    "# Print the output of titanic.tail(10)\n",
    "print(titanic.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other transformations with .apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             not_indexed_same=mutated or self.mutated)\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_wrap_applied_output\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m   4220\u001b[0m             return self._concat_objects(keys, values,\n\u001b[1;32m-> 4221\u001b[1;33m                                         not_indexed_same=not_indexed_same)\n\u001b[0m\u001b[0;32m   4222\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_concat_objects\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3565\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3566\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3684\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 3685\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   3686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   3500\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[1;32m-> 3501\u001b[1;33m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[0;32m   3502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   3511\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3512\u001b[1;33m                                            allow_dups=False)\n\u001b[0m\u001b[0;32m   3513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   3805\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3806\u001b[1;33m                                                 copy=copy)\n\u001b[0m\u001b[0;32m   3807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   4413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4414\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-795fc554aed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'z(gdp)'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'regional spread(gdp)'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Apply the disparity function on regional: reg_disp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mreg_disp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisparity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Print the disparity of 'United States', 'United Kingdom', and 'China'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0m_group_selection_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             not_indexed_same=mutated or self.mutated)\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iterate_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_wrap_applied_output\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m   4219\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m             return self._concat_objects(keys, values,\n\u001b[1;32m-> 4221\u001b[1;33m                                         not_indexed_same=not_indexed_same)\n\u001b[0m\u001b[0;32m   4222\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_concat_objects\u001b[1;34m(self, keys, values, not_indexed_same)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3564\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3565\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3566\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3568\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reindex_axis'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3683\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3684\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[1;32m-> 3685\u001b[1;33m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[0;32m   3686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3687\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   3499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3500\u001b[0m             frame = frame._reindex_index(index, method, copy, level,\n\u001b[1;32m-> 3501\u001b[1;33m                                          fill_value, limit, tolerance)\n\u001b[0m\u001b[0;32m   3502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3503\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   3510\u001b[0m         return self._reindex_with_indexers({0: [new_index, indexer]},\n\u001b[0;32m   3511\u001b[0m                                            \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3512\u001b[1;33m                                            allow_dups=False)\n\u001b[0m\u001b[0;32m   3513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m     def _reindex_columns(self, new_columns, method, copy, level,\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   3804\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3805\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3806\u001b[1;33m                                                 copy=copy)\n\u001b[0m\u001b[0;32m   3807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3808\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   4412\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4414\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3558\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3562\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "# Group gapminder_2010 by 'region': regional\n",
    "regional = gapminder_2010.groupby('region')\n",
    "\n",
    "def disparity(gr):\n",
    "    # Compute the spread of gr['gdp']: s\n",
    "    s = gr['gdp'].max() - gr['gdp'].min()\n",
    "    # Compute the z-score of gr['gdp']:\n",
    "    z = (gr['gdp'] - gr['gdp'].mean())/gr['gdp'].std()\n",
    "    \n",
    "    return pd.DataFrame({'z(gdp)': z, 'regional spread(gdp)':s})\n",
    "# Apply the disparity function on regional: reg_disp\n",
    "reg_disp = regional.apply(disparity)\n",
    "\n",
    "# Print the disparity of 'United States', 'United Kingdom', and 'China'\n",
    "print(reg_disp.loc[['United States', 'United Kingdom', 'China']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>fertility</th>\n",
       "      <th>life</th>\n",
       "      <th>population</th>\n",
       "      <th>child_mortality</th>\n",
       "      <th>gdp</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.671</td>\n",
       "      <td>33.639</td>\n",
       "      <td>10474903.0</td>\n",
       "      <td>339.70</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.711</td>\n",
       "      <td>65.475</td>\n",
       "      <td>1817098.0</td>\n",
       "      <td>122.67</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.653</td>\n",
       "      <td>47.953</td>\n",
       "      <td>11654905.0</td>\n",
       "      <td>247.30</td>\n",
       "      <td>5693.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.425</td>\n",
       "      <td>34.604</td>\n",
       "      <td>5337063.0</td>\n",
       "      <td>305.20</td>\n",
       "      <td>4573.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.250</td>\n",
       "      <td>63.775</td>\n",
       "      <td>58653.0</td>\n",
       "      <td>72.78</td>\n",
       "      <td>5008.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>1964</td>\n",
       "      <td>3.068</td>\n",
       "      <td>65.388</td>\n",
       "      <td>21966478.0</td>\n",
       "      <td>57.43</td>\n",
       "      <td>8227.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armenia</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.161</td>\n",
       "      <td>67.714</td>\n",
       "      <td>2138133.0</td>\n",
       "      <td>66.85</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aruba</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.059</td>\n",
       "      <td>67.113</td>\n",
       "      <td>57031.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5505.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>1964</td>\n",
       "      <td>3.154</td>\n",
       "      <td>70.650</td>\n",
       "      <td>11122567.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>16098.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.795</td>\n",
       "      <td>70.160</td>\n",
       "      <td>7220812.0</td>\n",
       "      <td>34.20</td>\n",
       "      <td>13915.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azerbaijan</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.468</td>\n",
       "      <td>62.701</td>\n",
       "      <td>4440733.0</td>\n",
       "      <td>93.61</td>\n",
       "      <td>5751.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahamas</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.220</td>\n",
       "      <td>64.189</td>\n",
       "      <td>133709.0</td>\n",
       "      <td>48.56</td>\n",
       "      <td>18160.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bahrain</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.192</td>\n",
       "      <td>57.182</td>\n",
       "      <td>181833.0</td>\n",
       "      <td>138.90</td>\n",
       "      <td>24751.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.853</td>\n",
       "      <td>49.297</td>\n",
       "      <td>56071080.0</td>\n",
       "      <td>240.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbados</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.094</td>\n",
       "      <td>62.819</td>\n",
       "      <td>234455.0</td>\n",
       "      <td>64.70</td>\n",
       "      <td>5681.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belarus</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.601</td>\n",
       "      <td>73.480</td>\n",
       "      <td>8521413.0</td>\n",
       "      <td>33.42</td>\n",
       "      <td>4357.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.599</td>\n",
       "      <td>70.730</td>\n",
       "      <td>9384939.0</td>\n",
       "      <td>28.90</td>\n",
       "      <td>14995.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belize</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.420</td>\n",
       "      <td>62.241</td>\n",
       "      <td>103555.0</td>\n",
       "      <td>112.27</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benin</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.497</td>\n",
       "      <td>39.142</td>\n",
       "      <td>2561022.0</td>\n",
       "      <td>292.50</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bhutan</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.670</td>\n",
       "      <td>33.827</td>\n",
       "      <td>251419.0</td>\n",
       "      <td>311.78</td>\n",
       "      <td>997.0</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolivia</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.607</td>\n",
       "      <td>43.913</td>\n",
       "      <td>3668568.0</td>\n",
       "      <td>265.40</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <td>1964</td>\n",
       "      <td>3.619</td>\n",
       "      <td>62.814</td>\n",
       "      <td>3357005.0</td>\n",
       "      <td>117.16</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Botswana</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.681</td>\n",
       "      <td>52.035</td>\n",
       "      <td>579518.0</td>\n",
       "      <td>152.80</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.953</td>\n",
       "      <td>56.521</td>\n",
       "      <td>82021855.0</td>\n",
       "      <td>154.20</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brunei</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.227</td>\n",
       "      <td>64.599</td>\n",
       "      <td>95191.0</td>\n",
       "      <td>83.12</td>\n",
       "      <td>67522.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulgaria</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.181</td>\n",
       "      <td>71.140</td>\n",
       "      <td>8140705.0</td>\n",
       "      <td>45.60</td>\n",
       "      <td>6110.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burkina Faso</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.414</td>\n",
       "      <td>36.331</td>\n",
       "      <td>5195464.0</td>\n",
       "      <td>331.00</td>\n",
       "      <td>711.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burundi</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.138</td>\n",
       "      <td>42.543</td>\n",
       "      <td>3154474.0</td>\n",
       "      <td>241.60</td>\n",
       "      <td>603.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cambodia</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.909</td>\n",
       "      <td>41.900</td>\n",
       "      <td>5983575.0</td>\n",
       "      <td>238.67</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cameroon</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.890</td>\n",
       "      <td>43.303</td>\n",
       "      <td>5909450.0</td>\n",
       "      <td>262.80</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syria</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.555</td>\n",
       "      <td>55.028</td>\n",
       "      <td>5202606.0</td>\n",
       "      <td>145.60</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.128</td>\n",
       "      <td>66.700</td>\n",
       "      <td>12631000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3407.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tajikistan</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.433</td>\n",
       "      <td>57.840</td>\n",
       "      <td>2424189.0</td>\n",
       "      <td>172.62</td>\n",
       "      <td>3769.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tanzania</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.801</td>\n",
       "      <td>44.731</td>\n",
       "      <td>11338515.0</td>\n",
       "      <td>233.90</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.151</td>\n",
       "      <td>57.133</td>\n",
       "      <td>30839333.0</td>\n",
       "      <td>128.00</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timor-Leste</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.347</td>\n",
       "      <td>35.724</td>\n",
       "      <td>537278.0</td>\n",
       "      <td>318.95</td>\n",
       "      <td>701.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Togo</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.734</td>\n",
       "      <td>42.846</td>\n",
       "      <td>1654451.0</td>\n",
       "      <td>254.60</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokelau</th>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tonga</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.117</td>\n",
       "      <td>62.839</td>\n",
       "      <td>71758.0</td>\n",
       "      <td>76.50</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinidad and Tobago</th>\n",
       "      <td>1964</td>\n",
       "      <td>4.664</td>\n",
       "      <td>64.422</td>\n",
       "      <td>883421.0</td>\n",
       "      <td>59.70</td>\n",
       "      <td>9362.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.107</td>\n",
       "      <td>44.903</td>\n",
       "      <td>4541457.0</td>\n",
       "      <td>244.70</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.029</td>\n",
       "      <td>48.313</td>\n",
       "      <td>31109820.0</td>\n",
       "      <td>221.90</td>\n",
       "      <td>5296.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkmenistan</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.663</td>\n",
       "      <td>56.181</td>\n",
       "      <td>1829697.0</td>\n",
       "      <td>132.98</td>\n",
       "      <td>7952.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uganda</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.078</td>\n",
       "      <td>46.332</td>\n",
       "      <td>7746988.0</td>\n",
       "      <td>204.30</td>\n",
       "      <td>965.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.070</td>\n",
       "      <td>72.190</td>\n",
       "      <td>44868657.0</td>\n",
       "      <td>45.18</td>\n",
       "      <td>6239.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.861</td>\n",
       "      <td>56.328</td>\n",
       "      <td>134478.0</td>\n",
       "      <td>162.20</td>\n",
       "      <td>5021.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.791</td>\n",
       "      <td>71.620</td>\n",
       "      <td>54006245.0</td>\n",
       "      <td>24.20</td>\n",
       "      <td>15067.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>1964</td>\n",
       "      <td>3.222</td>\n",
       "      <td>70.330</td>\n",
       "      <td>197094531.0</td>\n",
       "      <td>27.70</td>\n",
       "      <td>20338.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>1964</td>\n",
       "      <td>2.858</td>\n",
       "      <td>68.455</td>\n",
       "      <td>2664775.0</td>\n",
       "      <td>58.60</td>\n",
       "      <td>7644.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uzbekistan</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.777</td>\n",
       "      <td>60.682</td>\n",
       "      <td>9888629.0</td>\n",
       "      <td>163.99</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanuatu</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.836</td>\n",
       "      <td>48.853</td>\n",
       "      <td>72131.0</td>\n",
       "      <td>137.70</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.495</td>\n",
       "      <td>61.825</td>\n",
       "      <td>8759890.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>13789.0</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.464</td>\n",
       "      <td>61.604</td>\n",
       "      <td>38898597.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virgin Islands (U.S.)</th>\n",
       "      <td>1964</td>\n",
       "      <td>5.698</td>\n",
       "      <td>65.198</td>\n",
       "      <td>46122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Bank and Gaza</th>\n",
       "      <td>1964</td>\n",
       "      <td>8.041</td>\n",
       "      <td>51.679</td>\n",
       "      <td>1181587.0</td>\n",
       "      <td>165.32</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Sahara</th>\n",
       "      <td>1964</td>\n",
       "      <td>6.562</td>\n",
       "      <td>39.880</td>\n",
       "      <td>46308.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen, Rep.</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.385</td>\n",
       "      <td>36.068</td>\n",
       "      <td>5527652.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.240</td>\n",
       "      <td>46.574</td>\n",
       "      <td>3430747.0</td>\n",
       "      <td>192.30</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>1964</td>\n",
       "      <td>7.347</td>\n",
       "      <td>52.993</td>\n",
       "      <td>4279524.0</td>\n",
       "      <td>131.10</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã…land</th>\n",
       "      <td>1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Year  fertility    life   population  child_mortality  \\\n",
       "Country                                                                         \n",
       "Afghanistan             1964      7.671  33.639   10474903.0           339.70   \n",
       "Albania                 1964      5.711  65.475    1817098.0           122.67   \n",
       "Algeria                 1964      7.653  47.953   11654905.0           247.30   \n",
       "Angola                  1964      7.425  34.604    5337063.0           305.20   \n",
       "Antigua and Barbuda     1964      4.250  63.775      58653.0            72.78   \n",
       "Argentina               1964      3.068  65.388   21966478.0            57.43   \n",
       "Armenia                 1964      4.161  67.714    2138133.0            66.85   \n",
       "Aruba                   1964      4.059  67.113      57031.0              NaN   \n",
       "Australia               1964      3.154  70.650   11122567.0            22.70   \n",
       "Austria                 1964      2.795  70.160    7220812.0            34.20   \n",
       "Azerbaijan              1964      5.468  62.701    4440733.0            93.61   \n",
       "Bahamas                 1964      4.220  64.189     133709.0            48.56   \n",
       "Bahrain                 1964      7.192  57.182     181833.0           138.90   \n",
       "Bangladesh              1964      6.853  49.297   56071080.0           240.40   \n",
       "Barbados                1964      4.094  62.819     234455.0            64.70   \n",
       "Belarus                 1964      2.601  73.480    8521413.0            33.42   \n",
       "Belgium                 1964      2.599  70.730    9384939.0            28.90   \n",
       "Belize                  1964      6.420  62.241     103555.0           112.27   \n",
       "Benin                   1964      6.497  39.142    2561022.0           292.50   \n",
       "Bhutan                  1964      6.670  33.827     251419.0           311.78   \n",
       "Bolivia                 1964      6.607  43.913    3668568.0           265.40   \n",
       "Bosnia and Herzegovina  1964      3.619  62.814    3357005.0           117.16   \n",
       "Botswana                1964      6.681  52.035     579518.0           152.80   \n",
       "Brazil                  1964      5.953  56.521   82021855.0           154.20   \n",
       "Brunei                  1964      6.227  64.599      95191.0            83.12   \n",
       "Bulgaria                1964      2.181  71.140    8140705.0            45.60   \n",
       "Burkina Faso            1964      6.414  36.331    5195464.0           331.00   \n",
       "Burundi                 1964      7.138  42.543    3154474.0           241.60   \n",
       "Cambodia                1964      6.909  41.900    5983575.0           238.67   \n",
       "Cameroon                1964      5.890  43.303    5909450.0           262.80   \n",
       "...                      ...        ...     ...          ...              ...   \n",
       "Syria                   1964      7.555  55.028    5202606.0           145.60   \n",
       "Taiwan                  1964      5.128  66.700   12631000.0              NaN   \n",
       "Tajikistan              1964      6.433  57.840    2424189.0           172.62   \n",
       "Tanzania                1964      6.801  44.731   11338515.0           233.90   \n",
       "Thailand                1964      6.151  57.133   30839333.0           128.00   \n",
       "Timor-Leste             1964      6.347  35.724     537278.0           318.95   \n",
       "Togo                    1964      6.734  42.846    1654451.0           254.60   \n",
       "Tokelau                 2006        NaN  69.000       1170.0              NaN   \n",
       "Tonga                   1964      7.117  62.839      71758.0            76.50   \n",
       "Trinidad and Tobago     1964      4.664  64.422     883421.0            59.70   \n",
       "Tunisia                 1964      7.107  44.903    4541457.0           244.70   \n",
       "Turkey                  1964      6.029  48.313   31109820.0           221.90   \n",
       "Turkmenistan            1964      6.663  56.181    1829697.0           132.98   \n",
       "Uganda                  1964      7.078  46.332    7746988.0           204.30   \n",
       "Ukraine                 1964      2.070  72.190   44868657.0            45.18   \n",
       "United Arab Emirates    1964      6.861  56.328     134478.0           162.20   \n",
       "United Kingdom          1964      2.791  71.620   54006245.0            24.20   \n",
       "United States           1964      3.222  70.330  197094531.0            27.70   \n",
       "Uruguay                 1964      2.858  68.455    2664775.0            58.60   \n",
       "Uzbekistan              1964      6.777  60.682    9888629.0           163.99   \n",
       "Vanuatu                 1964      6.836  48.853      72131.0           137.70   \n",
       "Venezuela               1964      6.495  61.825    8759890.0            72.00   \n",
       "Vietnam                 1964      6.464  61.604   38898597.0            95.00   \n",
       "Virgin Islands (U.S.)   1964      5.698  65.198      46122.0              NaN   \n",
       "West Bank and Gaza      1964      8.041  51.679    1181587.0           165.32   \n",
       "Western Sahara          1964      6.562  39.880      46308.0              NaN   \n",
       "Yemen, Rep.             1964      7.385  36.068    5527652.0              NaN   \n",
       "Zambia                  1964      7.240  46.574    3430747.0           192.30   \n",
       "Zimbabwe                1964      7.347  52.993    4279524.0           131.10   \n",
       "Ã…land                   1997        NaN  78.900          NaN              NaN   \n",
       "\n",
       "                            gdp                      region  \n",
       "Country                                                      \n",
       "Afghanistan              1182.0                  South Asia  \n",
       "Albania                  3023.0       Europe & Central Asia  \n",
       "Algeria                  5693.0  Middle East & North Africa  \n",
       "Angola                   4573.0          Sub-Saharan Africa  \n",
       "Antigua and Barbuda      5008.0                     America  \n",
       "Argentina                8227.0                     America  \n",
       "Armenia                  2823.0       Europe & Central Asia  \n",
       "Aruba                    5505.0                     America  \n",
       "Australia               16098.0         East Asia & Pacific  \n",
       "Austria                 13915.0       Europe & Central Asia  \n",
       "Azerbaijan               5751.0       Europe & Central Asia  \n",
       "Bahamas                 18160.0                     America  \n",
       "Bahrain                 24751.0  Middle East & North Africa  \n",
       "Bangladesh               1138.0                  South Asia  \n",
       "Barbados                 5681.0                     America  \n",
       "Belarus                  4357.0       Europe & Central Asia  \n",
       "Belgium                 14995.0       Europe & Central Asia  \n",
       "Belize                   2114.0                     America  \n",
       "Benin                    1159.0          Sub-Saharan Africa  \n",
       "Bhutan                    997.0                  South Asia  \n",
       "Bolivia                  2971.0                     America  \n",
       "Bosnia and Herzegovina   2152.0       Europe & Central Asia  \n",
       "Botswana                 1038.0          Sub-Saharan Africa  \n",
       "Brazil                   4707.0                     America  \n",
       "Brunei                  67522.0         East Asia & Pacific  \n",
       "Bulgaria                 6110.0       Europe & Central Asia  \n",
       "Burkina Faso              711.0          Sub-Saharan Africa  \n",
       "Burundi                   603.0          Sub-Saharan Africa  \n",
       "Cambodia                 1548.0         East Asia & Pacific  \n",
       "Cameroon                 1910.0          Sub-Saharan Africa  \n",
       "...                         ...                         ...  \n",
       "Syria                    2894.0  Middle East & North Africa  \n",
       "Taiwan                   3407.0         East Asia & Pacific  \n",
       "Tajikistan               3769.0       Europe & Central Asia  \n",
       "Tanzania                 1176.0          Sub-Saharan Africa  \n",
       "Thailand                 1725.0         East Asia & Pacific  \n",
       "Timor-Leste               701.0         East Asia & Pacific  \n",
       "Togo                     1483.0          Sub-Saharan Africa  \n",
       "Tokelau                     NaN         East Asia & Pacific  \n",
       "Tonga                    1610.0         East Asia & Pacific  \n",
       "Trinidad and Tobago      9362.0                     America  \n",
       "Tunisia                  2575.0  Middle East & North Africa  \n",
       "Turkey                   5296.0       Europe & Central Asia  \n",
       "Turkmenistan             7952.0       Europe & Central Asia  \n",
       "Uganda                    965.0          Sub-Saharan Africa  \n",
       "Ukraine                  6239.0       Europe & Central Asia  \n",
       "United Arab Emirates     5021.0  Middle East & North Africa  \n",
       "United Kingdom          15067.0       Europe & Central Asia  \n",
       "United States           20338.0                     America  \n",
       "Uruguay                  7644.0                     America  \n",
       "Uzbekistan               2636.0       Europe & Central Asia  \n",
       "Vanuatu                  1553.0         East Asia & Pacific  \n",
       "Venezuela               13789.0                     America  \n",
       "Vietnam                  1285.0         East Asia & Pacific  \n",
       "Virgin Islands (U.S.)       NaN                     America  \n",
       "West Bank and Gaza       1237.0  Middle East & North Africa  \n",
       "Western Sahara              NaN  Middle East & North Africa  \n",
       "Yemen, Rep.                 NaN  Middle East & North Africa  \n",
       "Zambia                   3214.0          Sub-Saharan Africa  \n",
       "Zimbabwe                 1976.0          Sub-Saharan Africa  \n",
       "Ã…land                       NaN       Europe & Central Asia  \n",
       "\n",
       "[204 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gapminder_2010[~gapminder_2010.index.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and filtering with .apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "female    0.913043\n",
      "male      0.312500\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a groupby object using titanic over the 'sex' column: by_sex\n",
    "by_sex = titanic.groupby('sex')\n",
    "\n",
    "def c_deck_survival(gr):\n",
    "\n",
    "    c_passengers = gr['cabin'].str.startswith('C').fillna(False)\n",
    "\n",
    "    return gr.loc[c_passengers, 'survived'].mean()\n",
    "\n",
    "# Call by_sex.apply with the function c_deck_survival and print the result\n",
    "c_surv_by_sex = by_sex.apply(c_deck_survival)\n",
    "\n",
    "# Print the survival rates\n",
    "print(c_surv_by_sex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and filtering with .filter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Company'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-ba8a4732ad1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Group sales by 'Company': by_company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mby_company\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Company'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Compute the sum of the 'Units' of by_company: by_com_sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   6657\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   6658\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6659\u001b[1;33m                        observed=observed, **kwargs)\n\u001b[0m\u001b[0;32m   6660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6661\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                                                     \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willy huang\\python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m   3289\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3290\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3291\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3292\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3293\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV file into a DataFrame: sales\n",
    "#sales = pd.read_csv('sales.csv', index_col='Date', parse_dates=True)\n",
    "\n",
    "# Group sales by 'Company': by_company\n",
    "by_company = sales.groupby('Company')\n",
    "\n",
    "# Compute the sum of the 'Units' of by_company: by_com_sum\n",
    "by_com_sum = by_company['Units'].apply(sum)\n",
    "print(by_com_sum)\n",
    "\n",
    "# Filter 'Units' where the sum is > 35: by_com_filt\n",
    "by_com_filt = by_company.filter(lambda g:g['Units'].sum() > 35)\n",
    "print(by_com_filt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and grouping with .map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "over 10     0.366748\n",
      "under 10    0.609756\n",
      "Name: survived, dtype: float64\n",
      "age       pclass\n",
      "over 10   1         0.617555\n",
      "          2         0.380392\n",
      "          3         0.238897\n",
      "under 10  1         0.750000\n",
      "          2         1.000000\n",
      "          3         0.446429\n",
      "Name: survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the Boolean Series: under10\n",
    "under10 = (titanic['age'] < 10).map({True:'under 10', False:'over 10'})\n",
    "\n",
    "# Group by under10 and compute the survival rate\n",
    "survived_mean_1 = titanic.groupby(under10)['survived'].msean()\n",
    "print(survived_mean_1)\n",
    "\n",
    "# Group by under10 and pclass and compute the survival rate\n",
    "survived_mean_2 = titanic.groupby([under10, 'pclass'])['survived'].mean()\n",
    "print(survived_mean_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
